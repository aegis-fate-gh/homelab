# To run:
# ansible-playbook playbooks/jovian-prod/helm-base.yml -i inventories/eos.yml --become-password-file=credentials/ansible_eos_password.txt
# To Test:
# ansible-playbook playbooks/jovian-prod/helm-base.yml --check -i inventories/eos.yml --become-password-file=credentials/ansible_eos_password.txt
---
- name: Configure helm repos and base infrastructure level charts within the Jovian Cluster. Used after initial-config
  hosts: jupiter-01
  remote_user: ansible
  become: true
  vars_files:
    - ./helm_values/rancher.yml
    - ./helm_values/ceph-csi.yml
    - ./helm_values/smb.yml
    - ./helm_values/cloudflare.yml

  tasks:
    - name: Install helm repos
      kubernetes.core.helm_repository:
        name: "{{ repo_list.name }}"
        repo_url: "{{ repo_list.repo }}"
        state: present
      loop:
        - { name: 'rancher-stable', repo: 'https://releases.rancher.com/server-charts/stable' }
        - { name: 'ceph-csi', repo: 'https://ceph.github.io/csi-charts' }
        - { name: 'metallb', repo: 'https://metallb.github.io/metallb' }
        - { name: 'traefik', repo: 'https://helm.traefik.io/traefik' }
        - { name: 'csi-driver-smb', repo: 'https://raw.githubusercontent.com/kubernetes-csi/csi-driver-smb/master/charts' }
        - { name: 'backube', repo: 'https://backube.github.io/helm-charts/' }
        - { name: 'csi-driver-nfs', repo: 'https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts' }
      loop_control:
        loop_var: repo_list

    # https://github.com/metallb/metallb
    - name: Deploy Metallb
      kubernetes.core.helm:
        name: metallb
        chart_ref: metallb/metallb
        release_namespace: metallb-system
        chart_version: v0.14.9
        update_repo_cache: true
        create_namespace: true
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        wait: true
      
    - name: Copy MetalLB Config  
      ansible.builtin.copy:
        src: ./helm_values/metallb.yml
        dest: /tmp/metallb.yaml
        owner: ansible
        group: ansible

    - name: Apply the Metallb config
      ansible.builtin.shell: |
        kubectl apply -f /tmp/metallb.yaml

    # https://github.com/cert-manager/cert-manager
    - name: Deploy Cert manager
      kubernetes.core.helm:
        name: cert-manager
        chart_ref: jetstack/cert-manager
        release_namespace: cert-manager
        chart_version: v1.17.1
        update_repo_cache: true
        create_namespace: true
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        wait: true
        set_values:
          - value: crds.enabled=true

    # https://github.com/ceph/ceph-csi
    # https://devopstales.github.io/kubernetes/k8s-cephfs-storage-with-csi-driver/
    - name: Deploy the Cephfs Storage CSI
      kubernetes.core.helm:
        name: ceph-csi-cephfs
        chart_ref: ceph-csi/ceph-csi-cephfs
        release_namespace: ceph-csi-cephfs
        chart_version: v3.13.1
        update_repo_cache: true
        create_namespace: true
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        wait: true
        values:
          csiConfig:
            - clusterID: "{{ CLUSTER_ID }}"
              monitors:
                - 10.1.100.30:6789
                - 10.1.100.31:6789
                - 10.1.100.32:6789
              cephFS:
                subvolumeGroup: "csi"
          secret:
            name: csi-cephfs-secret
            adminID: admin
            adminKey: "{{ ADMIN_KEY }}"
            create: true
          storageClass:
            create: true
            name: k8s-cephfs
            clusterID: "{{ CLUSTER_ID }}"
            # (required) CephFS filesystem name into which the volume shall be created
            fsName: eos-fs
            reclaimPolicy: Delete
            allowVolumeExpansion: true
            volumeNamePrefix: "jovian-k3s-"
            provisionerSecret: csi-cephfs-secret
            controllerExpandSecret: csi-cephfs-secret
            nodeStageSecret: csi-cephfs-secret

    - name: Create Traefik PVC
      kubernetes.core.k8s:
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        state: present
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: traefik-pvc
            namespace: kube-system
          spec:
            accessModes:
              - ReadWriteOnce
            storageClassName: k8s-cephfs
            resources:
              requests:
                storage: 128Mi

    # https://github.com/traefik/traefik-helm-chart
    - name: Deploy Traefik
      kubernetes.core.helm:
        name: traefik
        chart_ref: traefik/traefik
        release_namespace: kube-system
        chart_version: v34.5.0
        update_repo_cache: true
        create_namespace: true
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        wait: true
        values:
          deployment:
            enabled: true
            replicas: 1
          logs:
            general:
              level: INFO
            access:
              enabled: true
          ingressClass:
            enabled: true
            isDefaultClass: true
          rbac:
            enabled: true
          api:
            insecure: true
          ingressRoute:
            dashboard:
              enabled: true
          traefik:
            expose:
              default: true
          providers:
            kubernetesCRD:
              enabled: true
              allowCrossNamespace: true
              allowExternalNameServices: true
            kubernetesIngress:
              enabled: true
              publishedService:
                enabled: true
          ports:
            traefik:
              expose:
                default: true
          service:
            enabled: true
            type: LoadBalancer
            annotations:
              metallb.io/address-pool: prod-pool
              metallb.io/loadBalancerIPs: 192.168.6.3
            ports:
            - protocol: TCP
              port: 80
              name: web
              targetPort: 8000
            - protocol: TCP
              port: 443
              name: websecure
              targetPort: 8443
            - protocol: TCP
              port: 8080
              name: admin
              targetPort: 8080
          persistence:
            enabled: true
            storageClass: k8s-cephfs
            existingClaim: traefik-pvc
          # certificatesResolvers:
          #   cloudflare:
          #     acme:
          #       email: "{{ CLOUDFLARE_EMAIL }}"
          #       storage: "/data/acme.json"
          #       dnsChallenge:
          #         provider: cloudflare
          #           - CF_DNS_API_TOKEN: "{{ CLOUDFLARE_TOKEN }}"

    # https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/rancher-v2-10-3/
    # To get available stable versions, run this on a control plane node: helm search repo rancher-stable/rancher --versions
    - name: Deploy Rancher
      kubernetes.core.helm:
        name: rancher
        chart_ref: rancher-stable/rancher 
        release_namespace: cattle-system
        chart_version: v2.10.3
        update_repo_cache: true
        create_namespace: true
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        wait: true
        values:
          hostname: "{{ rancher_hostname }}"
          bootstrapPassword: "{{ rancher_bootstrapPassword }}"
          service:
            enabled: true
            type: LoadBalancer
            annotations:
              metallb.io/address-pool: prod-pool
              metallb.io/loadBalancerIPs: 192.168.6.4

    # https://github.com/kubernetes-csi/external-snapshotter/
    # Ignore errors set to allow for running this playbook more than once
    - name: Install Snapshot and Volume Group Snapshot CRDs
      ansible.builtin.shell: |
        kubectl kustomize https://github.com/kubernetes-csi/external-snapshotter/client/config/crd | kubectl create -f -
      ignore_errors: true

    - name: Install the Common Snapshot Controller
      ansible.builtin.shell: |
        kubectl -n kube-system kustomize https://github.com/kubernetes-csi/external-snapshotter/deploy/kubernetes/snapshot-controller | kubectl create -f -
      ignore_errors: true
    
    # https://github.com/ceph/ceph-csi/blob/devel/examples/cephfs/snapshotclass.yaml
    - name: Create the CephFS Snapshot class
      kubernetes.core.k8s:
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        state: present
        definition:
          apiVersion: snapshot.storage.k8s.io/v1
          kind: VolumeSnapshotClass
          metadata:
            name: csi-cephfsplugin-snapclass
          driver: cephfs.csi.ceph.com
          parameters:
            clusterID: "{{ CLUSTER_ID }}"
            csi.storage.k8s.io/snapshotter-secret-name: csi-cephfs-secret
            csi.storage.k8s.io/snapshotter-secret-namespace: ceph-csi-cephfs
          deletionPolicy: Delete

    # https://volsync.readthedocs.io/en/stable/installation/index.html
    # https://github.com/backube/volsync
    - name: Deploy VolSync
      kubernetes.core.helm:
        name: volsync
        chart_ref: backube/volsync
        release_namespace: volsync-system
        chart_version: v0.13.0
        update_repo_cache: true
        create_namespace: true
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        wait: true

    # https://github.com/kubernetes-csi/csi-driver-smb/tree/master/charts
    - name: Deploy the SMB CSI
      kubernetes.core.helm:
        name: csi-driver-smb
        chart_ref: csi-driver-smb/csi-driver-smb
        release_namespace: kube-system
        chart_version: v1.9.0
        update_repo_cache: true
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        wait: true

    # https://github.com/kubernetes-csi/csi-driver-nfs/tree/master/charts
    - name: Deploy the NFS CSI
      kubernetes.core.helm:
        name: csi-driver-nfs
        chart_ref: csi-driver-nfs/csi-driver-nfs
        release_namespace: kube-system
        chart_version: v4.9.0
        update_repo_cache: true
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        wait: true

    - name: Create the Jovian-Prod namespace
      kubernetes.core.k8s:
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        state: present
        definition:
          apiVersion: v1
          kind: Namespace
          metadata:
            name: jovian-prod
            labels:
              name: jovian-prod

    # https://github.com/kubernetes-csi/csi-driver-smb/blob/master/deploy/example/e2e_usage.md#prerequisite
    - name: Create SMB secrets
      ansible.builtin.shell: |
        kubectl create secret generic "{{ smb_list.name }}" -n jovian-prod --from-literal username="{{ smb_list.username }}" --from-literal password="{{ smb_list.password }}"
      loop:
        - { name: 'smb-silo-immich', username: "{{ immich_smb_user }}", password: "{{ immich_silo_smb_password }}"}
        - { name: 'smb-syn-immich', username: "{{ immich_smb_user }}", password: "{{ immich_syn_smb_password }}"}
        - { name: 'smb-media-manangers', username: "{{ mm_smb_user }}", password: "{{ mm_smb_password }}"}
      loop_control:
        loop_var: smb_list
      ignore_errors: true

    # https://github.com/kubernetes-csi/csi-driver-nfs/blob/master/deploy/example/README.md
    - name: Create the Media NFS Storage Class in Jovian-Prod
      kubernetes.core.k8s:
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        state: present
        definition:
          apiVersion: v1
          kind: StorageClass
          metadata:
            name: nfs-csi-media
          provisioner: nfs.csi.k8s.io
          parameters:
            server: 192.168.100.162
            share: /var/nfs/shared/media
          volumeBindingMode: Immediate
          reclaimPolicy: Retain
          mountOptions:
            - nfsvers=3
    
    - name: Create SMB storage classes
      kubernetes.core.k8s:
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        state: present
        definition:
          apiVersion: v1
          kind: StorageClass
          metadata:
            name: "{{ smb_sc_list.name }}"
          provisioner: smb.csi.k8s.io
          parameters:
            source: "{{ smb_sc_list.source }}"
            csi.storage.k8s.io/node-stage-secret-name: "{{ smb_sc_list.name }}"
            csi.storage.k8s.io/node-stage-secret-namespace: "{{ smb_sc_list.namespace }}"
          volumeBindingMode: Immediate
          reclaimPolicy: Retain
          allowVolumeExpansion: true
      loop:
        - { name: 'smb-csi-immich-silo', source: '//192.168.100.162/immich', secret_name: 'smb-silo-immich', namespace: 'jovian-prod'}
        - { name: 'smb-csi-media', source: '//192.168.100.162/media', secret_name: 'smb-media-manangers', namespace: 'jovian-prod'}
        - { name: 'smb-csi-immich-syn', source: '//192.168.100.42/Dropbox', secret_name: 'smb-syn-immich', namespace: 'jovian-prod'}
      loop_control:
        loop_var: smb_sc_list
      ignore_errors: true


    - name: Create the needed node labels for the GPU Nodes
      kubernetes.core.k8s:
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        state: present
        definition:
          apiVersion: v1
          kind: Node
          metadata:
            name: "{{ gpu_list }}"
            labels: 
              gpu: "rtx4060"
              connection: "standard"
      loop:
        - ganymede-01
        - ganymede-02
        - ganymede-03
      loop_control:
        loop_var: gpu_list

    - name: Create the needed node labels for the VPN Nodes
      kubernetes.core.k8s:
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        state: present
        definition:
          apiVersion: v1
          kind: Node
          metadata:
            name: "{{ vpn_list }}"
            labels: 
              connection: "vpn"
      loop:
        - europa-01
        - europa-02
      loop_control:
        loop_var: vpn_list